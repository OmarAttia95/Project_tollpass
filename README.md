# Toll Pass Streaming Data Pipeline ğŸš—ğŸ“€

An end-to-end enterprise-grade data engineering project simulating real-time toll pass event streaming with fraud detection, GDPR masking, and a Kimball-style data warehouse on Snowflake.

## ğŸ“† Architecture Overview
This project mimics a **real-time streaming pipeline** from ingestion to BI-ready data warehouse using Azure, Databricks, Delta Lake, Snowflake, and ADF.

![ERD and Architecture Diagram](link-to-uploaded-image)

## âš–ï¸ Tech Stack
- **Azure**: Event Hub, ADLS Gen2, Key Vault, Function Apps, ADF
- **Data Processing**: Python, PySpark, Delta Lake
- **Orchestration**: Azure Data Factory, Snowflake Tasks
- **Storage Format**: AVRO â” JSON â” DELTA (partitioned by event_date)
- **Warehouse**: Snowflake (Bronze â” Silver â” Gold)
- **BI Tools**: Power BI (notebook + SQL access)
- **Security**: Key Vault secrets, GDPR masking policies (EU-compliant)

---

## âœ¨ Key Features
- âœ… **Simulated Streaming**: Azure Function App generates realistic toll events every minute
- âœ… **Secure Streaming**: Events pushed to Azure Event Hub with Managed Identity
- âœ… **Schema-on-Read**: Avro converted to JSON & structured with a defined schema
- âœ… **Delta Lake Storage**: Partitioned and optimized Delta format in ADLS
- âœ… **Orchestrated ETL**: ADF triggers Databricks notebook â” transfers results to Blob â” Snowflake COPY
- âœ… **Data Masking**: GDPR masking policy applied to `license_plate` column
- âœ… **Kimball DW Design**: Includes SCD Type 4, Junk Dim, Mini-Dim, Role-Playing Time Dim, and Fact Table

---

## ğŸ’¡ Data Flow

1. **Toll Event Generation**  
   Azure Function App â” Generates mock JSON events â” Sends to Event Hub

2. **Event Ingestion & Capture**  
   Azure Event Hub â” Avro Files â” Stored in ADLS Gen2 "capture" container

3. **Data Transformation**  
   Databricks â” Reads Avro â” Parses JSON â” Casts schema â” Adds `event_date` â” Writes to Delta format in "delta" container

4. **Orchestration**  
   ADF â” Triggers notebook + transfers Parquet to Snowflake external stage

5. **ELT in Snowflake**  
   Snowpipe & Streams â” Bronze â” Silver â” Gold with Snowflake Tasks

6. **BI Consumption**  
   Final Gold Tables exposed to Power BI

---

## ğŸ“‚ Folder Structure
```
/
|-- azure_function_app/              # Python code for event generation
|-- databricks_notebooks/           # Delta write logic (JSON from Avro)
|-- snowflake/
|   |-- bronze.sql
|   |-- silver.sql
|   |-- gold.sql
|   |-- masking_policy.sql
|-- ADF_pipeline_definitions/       # JSON ARM templates
|-- docs/
|   |-- ERD.png
|   |-- architecture.png
```

---

## ğŸš€ How to Run
1. Deploy Function App â” Configure Key Vault and Event Hub
2. Monitor ADLS for Avro ingestion (Event Hub capture)
3. Schedule Databricks notebook â” Output to Delta partitioned by `event_date`
4. ADF Pipeline â” Triggers notebook â” Pushes Parquet to Snowflake stage
5. Resume Snowflake Tasks (Bronze â” Silver â” Gold)
6. Query with Power BI

---

## ğŸ”’ GDPR Compliance
- `license_plate` column is masked based on user role
- Only roles `TOLL_ADMIN` and `COMPLIANCE_OFFICER` can view unmasked values

---

## ğŸŒŸ Highlights
- Reproduces a production-ready data streaming context from scratch
- Demonstrates partitioning, CDC, masking, and dimensional modeling
- Fully modular and easy to expand

---

## ğŸŒ Hashtags for Sharing
```
#DataEngineering #Snowflake #Azure #DeltaLake #ADF #Databricks #StreamingData #ETL #MedallionArchitecture #Kimball #GDPR #PowerBI #PySpark #EventHub #ModernDataStack
```

